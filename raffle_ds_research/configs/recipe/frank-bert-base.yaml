# @package _global_

defaults:
  # - override /dl_sampler: promote_trusted_sources
  # boost `ai_trainer` and `production` questions
  - override /model/encoder: bert-base
  # model name
  - override /model/gradients: kl_div
  # use the KL divergence from the model to the binary targets
  - override /trainer/strategy: deepspeed_2
  # DeepSpeed strategy ZeRO-2
  - override /model/optimizer: adam-cpu
  # use the CPU version of Adam (required by DeepSpeed ZeRO-2)s
  - _self_


seed: 2

dataset:
  train:
    # - frank.A.en-pos:train
    # - frank.A.en:train
    # - squad.en:train
    - msmarco.en:train
  validation:
    # - frank.A.en-pos:val
    # - frank.A.en:val
    # - squad.en:val
    - msmarco.en:val
  benchmark:
    # - frank.B.en-pos:val
    - frank.A.en:val
    - frank.B.en:val
    - msmarco.en:val

model:
  compile: true
  optimizer:
    lr: 1.41e-4
    weight_decay: 0
    eps: 1e-8
  gradients:
    self_supervision_weight: 0.0
    bm25_guidance_weight: 0.0

resources:
  num_workers: 2 # <--- 2 workers per GPU
  num_proc: 8 # <--- 8 workers to preprocess data on global rank zero

batch_size:
  effective: 64
  per_device: 16
  per_device_eval: 8
  per_device_predict: 2048

trainer:
  accelerator: gpu
  precision: 16-mixed
  detect_anomaly: false
  max_steps: 50_000
  limit_val_batches: 100
  val_check_interval: ${int_mul:${trainer.accumulate_grad_batches},500}
  inference_mode: false  # TODO: https://github.com/Lightning-AI/lightning/issues/17175#issuecomment-1487074273


collates:
  # Defines the configurations for `dataset_builder.HfBuilder._collate_config`
  train:
    n_sections: 24
    max_pos_sections: 8
    prefetch_n_sections: 128
    do_sample: false
    in_batch_negatives: true
  benchmark:
    n_sections: 300
    max_pos_sections: 100
    prefetch_n_sections: 512
    do_sample: false

schedule:
  period: 10_000
  reset_model_on_period_start: false
  benchmark_on_init: false
  parameters:
    faiss:
      mode: linear
      start: 0
      value: 1
      period: ${trainer.max_steps}

    bm25:
      mode: linear
      start: 1
      value: 0.1
      period: ${trainer.max_steps}


benchmark_search:
  faiss:
    factory: IVFauto,Flat

search:
  faiss:
    factory: OPQ32,IVFauto,PQ32x8
    metric: inner_product
    nprobe: 32
    train_size: 1_000_000
  bm25:
    text_key: text
    group_key: group_hash
    persistent: true