# @package _global_

defaults:
  - override /builder: retrieval
  - override /model/encoder: bert-base
  - override /model/gradients: kl_div
  - override /trainer/strategy: deepspeed
  - override /model/optimizer: adam-cpu
  - _self_


builder:
  name: frank.A.en.pos #+squad.en

model:
  embedding_size: 1_024
  use_pooler_layer: false
  optimizer:
    lr: 1e-4
    weight_decay: 0
  scheduler:
    total_iters: 100
  gradients:
    self_supervision_weight: 0.0
    bm25_guidance_weight: 0.0

resources:
  num_workers: 4
  num_proc: 4

batch_size:
  effective: 32
  per_device: 16
  per_device_eval: 8
  per_device_predict: 512

trainer:
  accelerator: gpu
  precision: 16-mixed
  detect_anomaly: false
  max_steps: 20_000
  limit_val_batches: 30
  val_check_interval: ${int_mul:${trainer.accumulate_grad_batches},100}


collates:
  # Defines the configurations for `dataset_builder.HfBuilder._collate_config`
  train:
    n_sections: 20
    max_pos_sections: 5
    prefetch_n_sections: 512
    do_sample: false
    question_max_length: 128
    section_max_length: 200
  eval:
    n_sections: 300
    max_pos_sections: 100
    prefetch_n_sections: 1000
    do_sample: false
    question_max_length: 128
    section_max_length: 200


indexes:
  update_freq: 2_000
  faiss:
    schedule: 0
  bm25:
    use_labels: true
    schedule: 1