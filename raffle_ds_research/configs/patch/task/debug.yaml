# @package _global_

defaults:
  - override /dataset/templates: encode_context
  - override /model/encoder: bert-tiny
  - _self_

seed: 1

model:
  gradients:
    section_chunk_size: null

benchmark:
  n_max_eval: 100
  on_init: true
  tune_parameters: true
  n_tuning_steps: 100
  search:
    faiss:
      factory: Flat

trainer:
  max_steps: 1000
  period: 300
  val_check_interval: 5
  n_max_eval: 100
  parameters:
    bm25: 1.0
    faiss:
      mode: linear
      start: 0.1s
      value: 1
      period: ${trainer.period}
      offset: ${trainer.period}

dataset:
  subset_size: null
  filter_unused_sections: false
  train: frank.A.en-pos:train
  validation: frank.A.en-pos:val
  benchmark:
    - frank.A.en-pos:val

batch_size:
  effective: 16
  per_device: 2
  per_device_eval: 2
  per_device_predict: 512

resources:
  num_workers: 1
  num_proc: 4

collates:
  train:
    n_sections: 5
    max_pos_sections: 2
    prefetch_n_sections: 32
    do_sample: true
    in_batch_negatives: true

  eval:
    n_sections: 128
    max_pos_sections: 32
    prefetch_n_sections: 256
