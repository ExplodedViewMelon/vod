faiss:
  factory: IVFauto,Flat
  metric: inner_product
  nprobe: 16
  train_size: null
  gpu:
    use_float16: true
    use_precomputed_tables: false
    keep_indices_on_cpu: false
    verbose: true
    shard: true
bm25:
  text_key: text
  group_key: group_hash
  persistent: true
  es_body:
    # defining a mapping will help: (1) optimize the performance, (2) save disk space
    mappings:
      properties:
        body: # section content
          type: text
        group: # group hash
          type: long
        section_id: # local section id
          type: long
        __row_idx__: # index of the section in the dataset
          type: unsigned_long
          # Prevents the inverted index and doc values from being created
          # enabled: false
    settings:
      # Defines changes to the text before tokenization and indexing
      analysis:
        analyzer:
          custom_analyzer:
            # token filters
            filter:
              - lowercase # Converts tokens to lowercase
              - stop # Removes tokens equivalent to english stopwords
              - asciifolding # Converts a-z, 1-9, and symbolic characters to their ASCII equivalent
            tokenizer: standard
            type: custom
      # Replicas are copies of the shards and provide reliability if a node is lost
      number_of_replicas: 0
      # Shards are used to parallelize work on an index
      number_of_shards: ${resources.n_devices} # <- scale the shards to the number of devices
      similarity:
        default:
          # texts which touch on several topics often benefit by choosing a larger b
          # most experiments seem to show the optimal b to be in a range of 0.3-0.9
          b: 0.75
          # should generally trend toward larger numbers when the text is a long and diverse
          # most experiments seem to show the optimal k1 to be in a range of 0.5-2.0
          k1: 1.2
          # By default, b has a value of 0.75 and k1 a value of 1.2
          type: BM25
