# @package _global_

defaults:
  - override /model/encoder: mini-lm-debug
  - _self_

seed: 1

model:
  gradients:
    anchor_weight: 0
    self_supervision_weight: 0
    guidance_weight: 0
    guidance: sparse

env:
  OMP_NUM_THREADS: 8

benchmark:
  n_max_eval: 100
  on_init: false
  tuning: null
  parameters:
    sparse: 1.0
    dense: 1.0

trainer:
  max_steps: 1000
  period: 300
  val_check_interval: 5
  n_max_eval: 100
  parameters:
    sparse: 0.0
    dense: 1.0

# dataset:
#   options:
#     subset_size: 200
#     filter_unused_sections: true

batch_size:
  effective: 16
  per_device: 2
  per_device_eval: 2
  per_device_predict: 512

resources:
  num_workers: 1
  num_proc: 4

collates:
  train:
    n_sections: 12
    max_pos_sections: 4
    support_size: 30
    prefetch_n_sections: 32
    do_sample: false
    in_batch_negatives: false
    post_filter: null

  benchmark:
    n_sections: 64
    max_pos_sections: 16
    prefetch_n_sections: 128
    do_sample: false
    post_filter: null

dataloaders:
  benchmark:
    batch_size: 3
