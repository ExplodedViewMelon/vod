# @package _global_

dataset:
  # Base search
  search:
    engines:
      dense:
        backend: qdrant
      sparse:
        backend: elasticsearch

  # Train/val splits
  training:
    queries:
      train:
        - __vars__:
            lang: ${languages}
          identifier: frank_a_{lang}_train
          name_or_path:
            _target_: vod_datasets.FrankDatasetLoader
            frank_split: A
            language: "{lang}"
            what: queries
          split: train
          link: frank_a_{lang}_sections
      val:
        - __vars__:
            lang: ${languages}
          identifier: frank_a_{lang}_val
          name_or_path:
            _target_: vod_datasets.FrankDatasetLoader
            frank_split: A
            language: "{lang}"
            what: queries
          split: validation
          link: frank_a_{lang}_sections
    sections:
      sections:
        - __vars__:
            lang: ${languages}
          identifier: frank_a_{lang}_sections
          name_or_path:
            _target_: vod_datasets.FrankDatasetLoader
            frank_split: A
            language: "{lang}"
            what: sections
          search:
            engines:
              sparse:
                # Make sure to set the current language to load `stopwords` accordingly.
                backend: elasticsearch
                language: "{lang}"

  # Benchmarks
  benchmark:
    - __vars__:
        lang: ${languages}
        frank_split: [A, B]
      queries:
        identifier: "frank_{frank_split}_{lang}_val"
        name_or_path:
          _target_: vod_datasets.FrankDatasetLoader
          frank_split: "{frank_split}"
          language: "{lang}"
          what: queries
        split: validation
      sections:
        identifier: "frank_{frank_split}_{lang}_val"
        name_or_path:
          _target_: vod_datasets.FrankDatasetLoader
          frank_split: "{frank_split}"
          language: "{lang}"
          what: sections
        search:
          engines:
            sparse:
              # Make sure to set the current language to load `stopwords` accordingly.
              backend: elasticsearch
              language: "{lang}"
